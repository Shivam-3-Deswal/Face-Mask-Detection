#!/usr/bin/env python
# coding: utf-8

# In[1]:


import cv2
import matplotlib.pyplot as plt
import os
import numpy as np
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
from tensorflow.keras.preprocessing.image import img_to_array
from tensorflow.keras.preprocessing.image import load_img


# In[2]:


cv2_base_dir = os.path.dirname(os.path.abspath(cv2.__file__)) 
haar_model = os.path.join(cv2_base_dir, 'data/haarcascade_frontalface_default.xml')
haar_data = cv2.CascadeClassifier('data.xml')
face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')


# In[3]:


capture = cv2.VideoCapture(0)
data = []
while True:
    flag,img = capture.read()
    if flag:
        faces = face_cascade.detectMultiScale(img)
        for x,y,w,h in faces:
            cv2.rectangle(img, (x,y), (x+w,y+h), (255,0,255), 4)
            face = img[y:y+h, x:x+w, :]
            face = cv2.resize(face,(50,50)) 
            
            data.append(face)
        cv2.imshow("Result",img)
        if cv2.waitKey(2) == 27 or len(data) >= 200:
            break
capture.release()
cv2.destroyAllWindows()


# In[4]:


np.save("without_mask.npy",data)


# In[5]:


capture = cv2.VideoCapture(0)
data = []
while True:
    flag,img = capture.read()
    if flag:
        faces = face_cascade.detectMultiScale(img)
        for x,y,w,h in faces:
            cv2.rectangle(img, (x,y), (x+w,y+h), (255,0,255), 4)
            face = img[y:y+h, x:x+w, :]
            face = cv2.resize(face,(50,50)) 
            
            data.append(face)
        cv2.imshow("Result",img)
        if cv2.waitKey(2) == 27 or len(data) >= 200:
            break
capture.release()
cv2.destroyAllWindows()


# In[6]:


np.save("with_mask.npy",data)


# In[ ]:




